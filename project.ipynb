{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "pip install --force-reinstall openai==1.8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datasets import load_dataset\n",
    "import pandas as pd\n",
    "from rouge import Rouge\n",
    "from openai import OpenAI\n",
    "import json\n",
    "from settings import *\n",
    "from utils import preprocess, prompt, score, utils\n",
    "import os \n",
    "\n",
    "from langchain.llms import OpenAI\n",
    "from langchain import HuggingFaceHub, LLMChain\n",
    "from langchain.prompts import load_prompt, PromptTemplate\n",
    "from tqdm import tqdm\n",
    "\n",
    "from langchain.prompts import PromptTemplate\n",
    "from langchain import LLMChain\n",
    "from transformers import AutoModelForCausalLM, AutoTokenizer, pipeline, GenerationConfig\n",
    "from langchain_community.llms.huggingface_pipeline import HuggingFacePipeline\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "import torch\n",
    "import numpy as np                                                              \n",
    "config = utils.load_json(CONFIG_DIR)\n",
    "np.random.seed(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>article</th>\n",
       "      <th>abstract</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>a review of the literature and an extensive me...</td>\n",
       "      <td>backgrounda review of the literature and an ex...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>nathan , as an oncology fellow , knew well tha...</td>\n",
       "      <td>t cells tell macrophages when to start making ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>temporary henna tattoos or pseudotattoo have b...</td>\n",
       "      <td>temporary henna tattoos or pseudotattoos have ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                             article   \n",
       "0  a review of the literature and an extensive me...  \\\n",
       "1  nathan , as an oncology fellow , knew well tha...   \n",
       "2  temporary henna tattoos or pseudotattoo have b...   \n",
       "\n",
       "                                            abstract  \n",
       "0  backgrounda review of the literature and an ex...  \n",
       "1  t cells tell macrophages when to start making ...  \n",
       "2  temporary henna tattoos or pseudotattoos have ...  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pubmed = utils.load_data(config['data_name'])\n",
    "pubmed.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1fd2b3c69edc4f69889ff777b2035e54",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/3 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "MODEL_NAME = \"mistralai/Mistral-7B-Instruct-v0.2\"\n",
    "cache_dir = \"/data/ephemeral/Youtube-Short-Generator/mistral\"\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(MODEL_NAME,cache_dir=cache_dir)\n",
    "tokenizer.pad_token_id = tokenizer.eos_token_id\n",
    "model = AutoModelForCausalLM.from_pretrained(\n",
    "    MODEL_NAME,\n",
    "    cache_dir=cache_dir)\n",
    "pipe = pipeline(\"text-generation\", model=model, tokenizer=tokenizer, max_new_tokens=100, device = 0, pad_token_id=tokenizer.eos_token_id)\n",
    "hf = HuggingFacePipeline(pipeline=pipe)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_summarization(df,save_name, iter_num = 5):\n",
    "    template = \"\"\"\n",
    "    <s>[INST]<>You are an abstractive summarizer that follows the output pattern.\n",
    "    Please revise the extracted summary based on the document. The revised summary should include the information in the extracted summary. Original Document: {document}<>[/INST]<\\s>.\n",
    "    \"\"\"\n",
    "    for i in range(iter_num):\n",
    "        response_list = []\n",
    "        for idx in tqdm(range(len(df))):\n",
    "            doc = df.iloc[idx, 0]\n",
    "            prompt = PromptTemplate(template=template, input_variables=[\"document\"])\n",
    "            llm_chain = LLMChain(prompt=prompt, llm=hf)\n",
    "            response = llm_chain.invoke(input = doc)['text']\n",
    "            if len(response) > 0:\n",
    "                response_list.append([response, df.iloc[idx, 1]])\n",
    "        df = pd.DataFrame(response_list, columns = ['generate', 'abstract'])\n",
    "        df.to_csv(os.path.join(OUT_DIR, f\"{save_name}_{i}.csv\"), index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1000/1000 [1:27:22<00:00,  5.24s/it]\n",
      "100%|██████████| 1000/1000 [1:11:29<00:00,  4.29s/it]\n",
      "100%|██████████| 1000/1000 [1:11:09<00:00,  4.27s/it]\n"
     ]
    }
   ],
   "source": [
    "save_name = 'mistral'\n",
    "test = pubmed.sample(n=1000)\n",
    "get_summarization(test, save_name, 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Get Rouge List From all Dataframe: 100%|██████████| 3/3 [00:22<00:00,  7.57s/it]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([0.22415016, 0.19500024, 0.20017621])"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "save_name = 'mistral'\n",
    "model_avg_rouge = score.get_rouge_list_from_all_df(save_name)\n",
    "model_avg_rouge"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "score.save_rouge_avg(model_avg_rouge,'mistral')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rouge List:  [0.22415016 0.19500024 0.20017621]\n",
      "Mean :0.206\n",
      "Standard Deviation:0.013\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(0.206, 0.013)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "score.statistic_from_rouge_list('mistral_result.npy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
