{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "pip install --force-reinstall openai==1.8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datasets import load_dataset\n",
    "import pandas as pd\n",
    "from rouge import Rouge\n",
    "from openai import OpenAI\n",
    "import json\n",
    "from settings import *\n",
    "from utils import preprocess, prompt, score, utils\n",
    "import os \n",
    "\n",
    "from langchain.llms import OpenAI\n",
    "from langchain import HuggingFaceHub, LLMChain\n",
    "from langchain.prompts import load_prompt, PromptTemplate\n",
    "from tqdm import tqdm\n",
    "\n",
    "from langchain.prompts import PromptTemplate\n",
    "from langchain import LLMChain\n",
    "from transformers import AutoModelForCausalLM, AutoTokenizer, pipeline\n",
    "from langchain_community.llms.huggingface_pipeline import HuggingFacePipeline\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "                                                             \n",
    "config = utils.load_json(CONFIG_DIR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>article</th>\n",
       "      <th>abstract</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>a review of the literature and an extensive me...</td>\n",
       "      <td>backgrounda review of the literature and an ex...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>nathan , as an oncology fellow , knew well tha...</td>\n",
       "      <td>t cells tell macrophages when to start making ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>temporary henna tattoos or pseudotattoo have b...</td>\n",
       "      <td>temporary henna tattoos or pseudotattoos have ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>care coordination is an important aspect of nu...</td>\n",
       "      <td>introductioncare coordination is an important ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>the laparoscopic removal of a cervical stump f...</td>\n",
       "      <td>a 43-year - old , who underwent a subtotal hys...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2964</th>\n",
       "      <td>to assess attitudes and practices of documenta...</td>\n",
       "      <td>purposes : to assess attitudes and practices o...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2965</th>\n",
       "      <td>hearts , isolated from wildtype zebrafish embr...</td>\n",
       "      <td>electrical gradients are critical for many bio...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2966</th>\n",
       "      <td>both f-18 fluorodeoxyglucose ( fdg ) and c-11 ...</td>\n",
       "      <td>a 10-year - boy post - operative , post - radi...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2967</th>\n",
       "      <td>monilethrix is an autosomal dominant disorder ...</td>\n",
       "      <td>congenital hypotrichosis may be due to a numbe...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2968</th>\n",
       "      <td>2005 after a detailed polyphasic study and rec...</td>\n",
       "      <td>we report the 3.3-mb draft genome of laceyella...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2969 rows Ã— 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                article   \n",
       "0     a review of the literature and an extensive me...  \\\n",
       "1     nathan , as an oncology fellow , knew well tha...   \n",
       "2     temporary henna tattoos or pseudotattoo have b...   \n",
       "3     care coordination is an important aspect of nu...   \n",
       "4     the laparoscopic removal of a cervical stump f...   \n",
       "...                                                 ...   \n",
       "2964  to assess attitudes and practices of documenta...   \n",
       "2965  hearts , isolated from wildtype zebrafish embr...   \n",
       "2966  both f-18 fluorodeoxyglucose ( fdg ) and c-11 ...   \n",
       "2967  monilethrix is an autosomal dominant disorder ...   \n",
       "2968  2005 after a detailed polyphasic study and rec...   \n",
       "\n",
       "                                               abstract  \n",
       "0     backgrounda review of the literature and an ex...  \n",
       "1     t cells tell macrophages when to start making ...  \n",
       "2     temporary henna tattoos or pseudotattoos have ...  \n",
       "3     introductioncare coordination is an important ...  \n",
       "4     a 43-year - old , who underwent a subtotal hys...  \n",
       "...                                                 ...  \n",
       "2964  purposes : to assess attitudes and practices o...  \n",
       "2965  electrical gradients are critical for many bio...  \n",
       "2966  a 10-year - boy post - operative , post - radi...  \n",
       "2967  congenital hypotrichosis may be due to a numbe...  \n",
       "2968  we report the 3.3-mb draft genome of laceyella...  \n",
       "\n",
       "[2969 rows x 2 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pubmed = utils.load_data(config['data_name'])\n",
    "pubmed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1d826407cc684872a9120df1e8724990",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/3 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "MODEL_NAME = \"mistralai/Mistral-7B-Instruct-v0.2\"\n",
    "cache_dir = \"/data/ephemeral/Youtube-Short-Generator/mistral\"\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(MODEL_NAME,cache_dir=cache_dir)\n",
    "tokenizer.pad_token_id = tokenizer.eos_token_id\n",
    "model = AutoModelForCausalLM.from_pretrained(MODEL_NAME,cache_dir=cache_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "pipe = pipeline(\"text-generation\", model=model, tokenizer=tokenizer, max_new_tokens=300, device = 0, pad_token_id=tokenizer.eos_token_id)\n",
    "hf = HuggingFacePipeline(pipeline=pipe)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "template = \"\"\"\n",
    "<s>[INST]<>You are an abstractive summarizer that follows the output pattern.\n",
    "Please revise the extracted summary based on the document. The revised summary should include the information in the extracted summary. Original Document: {document}<>[/INST]<\\s>.\n",
    "\"\"\"\n",
    "doc = pubmed.iloc[0, 0]\n",
    "prompt = PromptTemplate(template=template, input_variables=[\"document\"])\n",
    "llm_chain = LLMChain(prompt=prompt, llm=hf)\n",
    "response = llm_chain.invoke(input = doc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/data/ephemeral/Youtube-Short-Generator/results/mistral'"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "os.path.join(OUT_DIR, 'mistral')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_summarization(df,save_name, iter_num = 5):\n",
    "    template = \"\"\"\n",
    "    <s>[INST]<>You are an abstractive summarizer that follows the output pattern.\n",
    "    Please revise the extracted summary based on the document. The revised summary should include the information in the extracted summary. Original Document: {document}<>[/INST]<\\s>.\n",
    "    \"\"\"\n",
    "    for i in range(iter_num):\n",
    "        response_list = []\n",
    "        for idx in tqdm(range(len(df))):\n",
    "            doc = df.iloc[idx, 0]\n",
    "            prompt = PromptTemplate(template=template, input_variables=[\"document\"])\n",
    "            llm_chain = LLMChain(prompt=prompt, llm=hf)\n",
    "            response = llm_chain.invoke(input = doc)['text']\n",
    "            if len(response) > 0:\n",
    "                response_list.append([response, df.iloc[idx, 1]])\n",
    "        df = pd.DataFrame(response_list, columns = ['generate', 'abstract'])\n",
    "        df.to_csv(os.path.join(OUT_DIR, f\"{save_name}_{i}.csv\"), index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2/2 [00:28<00:00, 14.39s/it]\n",
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2/2 [00:25<00:00, 12.77s/it]\n",
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2/2 [00:25<00:00, 12.98s/it]\n",
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2/2 [00:25<00:00, 12.83s/it]\n",
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2/2 [00:25<00:00, 12.76s/it]\n"
     ]
    }
   ],
   "source": [
    "test = pubmed.iloc[:2]\n",
    "get_summarization(test, 'test')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_rouge_from_df(generate_df, rouge_type = 'rouge-l', metric = 'f'):\n",
    "    df = pd.read_csv(os.path.join(OUT_DIR, generate_df))   \n",
    "    value = 0\n",
    "    for idx, row in df.iterrows():\n",
    "        value_dic = score.get_Rouge_score(row['generate'], row['abstract'])\n",
    "        value += value_dic[rouge_type][metric]\n",
    "    return value / len(generate_df)\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['test_4.csv']"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[i for i in os.listdir(OUT_DIR) if '4' in i]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_rouge_from_all_df(save_name):\n",
    "    file_list = [i for i in os.listdir(OUT_DIR) if save_name in i]\n",
    "    value_list = []\n",
    "    for file in file_list:\n",
    "        value = get_rouge_from_df(file)\n",
    "        value_list.append(value)\n",
    "    return sum(value_list) / len(file_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = get_rouge_from_all_df('test')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
