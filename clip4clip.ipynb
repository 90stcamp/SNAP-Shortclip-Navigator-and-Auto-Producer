{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/root/Youtube-Short-Generator/.venv/lib/python3.8/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "import cv2\n",
    "import re\n",
    "\n",
    "import torch\n",
    "\n",
    "from transformers import CLIPTokenizer, CLIPTextModelWithProjection, CLIPTextModel,AutoTokenizer, CLIPVisionModelWithProjection, CLIPVisionModel\n",
    "from torchvision.transforms import Compose, Resize, CenterCrop, ToTensor, Normalize, InterpolationMode\n",
    "\n",
    "# !pip install torchvision==0.14\n",
    "# !pip install opencv-python # opencv-python-4.9.0.80"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "current_directory = os.getcwd()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model = CLIPTextModelWithProjection.from_pretrained(\"Searchium-ai/clip4clip-webvid150k\",cache_dir=current_directory)\n",
    "model = CLIPTextModel.from_pretrained(\"Searchium-ai/clip4clip-webvid150k\",cache_dir=current_directory)\n",
    "tokenizer = CLIPTokenizer.from_pretrained(\"Searchium-ai/clip4clip-webvid150k\",cache_dir=current_directory)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "search_sentence = \"Finland and Denmark have consistently topped the World Happiness Report as the happiest countries in the world. The annual happiness ranking, which began in 2012, measures happiness through various factors including relationships, income, and life satisfaction. Finland was named the happiest country in 2019, with Denmark coming in second place. The Nordic countries, including Norway, Iceland, and Sweden, also consistently rank high in the report.\"\n",
    "sentences = re.split(r'(?<!\\w\\.\\w.)(?<![A-Z][a-z]\\.)(?<=\\.|\\?)\\s', search_sentence)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Finland and Denmark have consistently topped the World Happiness Report as the happiest countries in the world.',\n",
       " 'The annual happiness ranking, which began in 2012, measures happiness through various factors including relationships, income, and life satisfaction.',\n",
       " 'Finland was named the happiest country in 2019, with Denmark coming in second place.',\n",
       " 'The Nordic countries, including Norway, Iceland, and Sweden, also consistently rank high in the report.']"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sentences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "texts_tensor = []\n",
    "for text in sentences:\n",
    "    inputs = tokenizer(text=text , return_tensors=\"pt\")\n",
    "    outputs = model(input_ids=inputs[\"input_ids\"], attention_mask=inputs[\"attention_mask\"])\n",
    "    final_output = outputs[1] / outputs[1].norm(dim=-1, keepdim=True) # final_output.shape : torch.Size([1, 512])\n",
    "    texts_tensor.append(final_output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "example = '/root/Youtube-Short-Generator/videos/test.mp4'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def video2image(video_path, frame_rate=1.0, size=224):\n",
    "    def preprocess(size, n_px):\n",
    "        return Compose([\n",
    "            Resize(size, interpolation=InterpolationMode.BICUBIC),            \n",
    "            CenterCrop(size),\n",
    "            lambda image: image.convert(\"RGB\"),\n",
    "            ToTensor(),\n",
    "            Normalize((0.48145466, 0.4578275, 0.40821073), (0.26862954, 0.26130258, 0.27577711)),\n",
    "        ])(n_px)\n",
    "    \n",
    "    cap = cv2.VideoCapture(video_path)\n",
    "    cap = cv2.VideoCapture(video_path, cv2.CAP_FFMPEG)\n",
    "    frameCount = int(cap.get(cv2.CAP_PROP_FRAME_COUNT))\n",
    "    fps = int(cap.get(cv2.CAP_PROP_FPS))+1\n",
    "\n",
    "    if fps < 1:\n",
    "        images = np.zeros([3, size, size], dtype=np.float32) \n",
    "        print(\"ERROR: problem reading video file: \", video_path)\n",
    "    else:\n",
    "        total_duration = (frameCount + fps - 1) // fps\n",
    "        start_sec, end_sec = 0, total_duration\n",
    "        interval = fps / frame_rate\n",
    "        frames_idx = np.floor(np.arange(start_sec*fps, end_sec*fps, interval))\n",
    "        ret = True     \n",
    "        images = np.zeros([len(frames_idx), 3, size, size], dtype=np.float32)\n",
    "            \n",
    "        for i, idx in enumerate(frames_idx):\n",
    "            cap.set(cv2.CAP_PROP_POS_FRAMES , idx)\n",
    "            ret, frame = cap.read()    \n",
    "            if not ret: break\n",
    "            frame = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)            \n",
    "            last_frame = i\n",
    "            images[i,:,:,:] = preprocess(size, Image.fromarray(frame).convert(\"RGB\"))\n",
    "            \n",
    "        images = images[:last_frame+1]\n",
    "    cap.release()\n",
    "    video_frames = torch.tensor(images)\n",
    "    return video_frames\n",
    "    \n",
    "# video = video2image(example)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "video = video2image(example)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1544, 3, 224, 224])"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "video.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = CLIPVisionModelWithProjection.from_pretrained(\"Searchium-ai/clip4clip-webvid150k\",cache_dir=current_directory)\n",
    "# model = CLIPVisionModel.from_pretrained(\"Searchium-ai/clip4clip-webvid150k\",cache_dir=current_directory)\n",
    "model = model.eval()\n",
    "visual_output = model(video)\n",
    "\n",
    "visual_output = visual_output[\"image_embeds\"]\n",
    "visual_output = visual_output / visual_output.norm(dim=-1, keepdim=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1544, 512])"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "visual_output.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "top_idx = []\n",
    "for st in texts_tensor:\n",
    "    dot_product_result = torch.matmul(st, visual_output.t())\n",
    "    dot_product_result.shape\n",
    "    _, top_indices = torch.topk(dot_product_result, k=20)\n",
    "    top_idx.append(top_indices)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[tensor([[1246,  108,  382, 1245,  529,  790,  458, 1243,  107, 1261,  417, 1259,\n",
       "            88,   74,  121,   53,   52,  418, 1425,  776]]),\n",
       " tensor([[1020,  152,  157,  217,  155,  156,  162, 1425,  158, 1245, 1019,  223,\n",
       "           227,  225,   69,  229,  909,  907,  228, 1219]]),\n",
       " tensor([[1261, 1246,  830, 1247, 1196,  767,  529,   90,   52, 1238,  567,  776,\n",
       "          1243,  458,  568,  768, 1235,  108,  928, 1258]]),\n",
       " tensor([[ 121,  382, 1261,   75,  186, 1478,   69, 1477,  875, 1247,   81,  914,\n",
       "            80,   73,   76,  119,   74,  229,  226,  225]])]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "top_idx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "flat_list = torch.cat(top_idx, dim=0).flatten()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "sorted_tensor = torch.sort(flat_list).values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([  52,   52,   53,   69,   69,   73,   74,   74,   75,   76,   80,   81,\n",
       "          88,   90,  107,  108,  108,  119,  121,  121,  152,  155,  156,  157,\n",
       "         158,  162,  186,  217,  223,  225,  225,  226,  227,  228,  229,  229,\n",
       "         382,  382,  417,  418,  458,  458,  529,  529,  567,  568,  767,  768,\n",
       "         776,  776,  790,  830,  875,  907,  909,  914,  928, 1019, 1020, 1196,\n",
       "        1219, 1235, 1238, 1243, 1243, 1245, 1245, 1246, 1246, 1247, 1247, 1258,\n",
       "        1259, 1261, 1261, 1261, 1425, 1425, 1477, 1478])"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sorted_tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[52, 53, 69, 73, 74, 75, 76, 80, 81, 88, 90], [107, 108, 119, 121, 152, 155, 156, 157], [158, 162, 186], [217, 223, 225, 226, 227, 228, 229], [382, 417, 418], [458], [529, 567, 568], [767, 768, 776, 790], [830, 875], [907, 909, 914, 928], [1019, 1020], [1196, 1219, 1235, 1238, 1243, 1245, 1246], [1247, 1258, 1259, 1261], [1425], [1477, 1478]]\n"
     ]
    }
   ],
   "source": [
    "def process_and_output(tensor):\n",
    "    result = []\n",
    "    tensor = tensor.tolist()  \n",
    "    \n",
    "    while tensor:\n",
    "        current_value = tensor[0]\n",
    "        start_range = current_value - 10\n",
    "        end_range = start_range + 60\n",
    "        \n",
    "        current_range_values = [num for num in range(start_range, end_range + 1) if num in tensor]\n",
    "        result.append(current_range_values)\n",
    "        \n",
    "        tensor = [num for num in tensor if num not in current_range_values]\n",
    "    \n",
    "    return result\n",
    "\n",
    "\n",
    "output = process_and_output(sorted_tensor)\n",
    "print(output)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Finland and Denmark have consistently topped the World Happiness Report as the happiest countries in the world.',\n",
       " 'The annual happiness ranking, which began in 2012, measures happiness through various factors including relationships, income, and life satisfaction.',\n",
       " 'Finland was named the happiest country in 2019, with Denmark coming in second place.',\n",
       " 'The Nordic countries, including Norway, Iceland, and Sweden, also consistently rank high in the report.']"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sentences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def convert_seconds_to_minutes_and_seconds(seconds):\n",
    "    minutes = seconds // 60\n",
    "    remaining_seconds = seconds % 60\n",
    "    return minutes, remaining_seconds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
